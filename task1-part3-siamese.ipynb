{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Face Verification using a Siamese Network","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport random\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd ## for reading csv file and wroking with dataframe operations\nfrom PIL import Image ## for image processing and output\nimport matplotlib.pyplot as plt\nimport random\nfrom tensorflow.keras.layers import *\ntf.__version__, np.__version__","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:40.417277Z","iopub.execute_input":"2023-09-11T18:38:40.417586Z","iopub.status.idle":"2023-09-11T18:38:47.410803Z","shell.execute_reply.started":"2023-09-11T18:38:40.417505Z","shell.execute_reply":"2023-09-11T18:38:47.409905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data","metadata":{}},{"cell_type":"code","source":"# Set paths\ndataset_folder = '/kaggle/input/iiitb-faces/IIITB-FACES'\n\ndef read_image(info):\n    path = os.path.join(dataset_folder, info[0], info[1])\n    img = cv2.imread(path)\n    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    \n    gray_img = cv2.equalizeHist(gray_img) # Apply histogram equalization\n    faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n    face_image = img\n    if(len(faces) > 0):\n        x, y, w, h = faces[0]\n        face_image = img[y:y+h, x:x+w]\n    face_image = cv2.resize(face_image, (350,350))\n    return face_image\n\ntest_list = {} \ntrain_list = {}\ntot_train_images = 0\ntot_test_images = 0\n\n# Loop through each person's folder\nfor person_folder in os.listdir(dataset_folder):\n    person_path = os.path.join(dataset_folder, person_folder)\n    person_images = [image_file for image_file in os.listdir(person_path)]\n    \n    # Shuffle the images\n    random.shuffle(person_images)\n    \n    # Calculate split point based on 80-20 ratio\n    split_index = int(0.8 * len(person_images))\n    \n    # Split images into train and test\n    for image_file in person_images[:split_index]:  \n        tot_train_images += 1\n        if person_folder in train_list:\n            train_list[person_folder].append(image_file)\n        else:\n            train_list[person_folder] = [image_file]\n        \n    for image_file in person_images[split_index:]:\n        tot_test_images += 1\n        if person_folder in test_list:\n            test_list[person_folder].append(image_file)\n        else:\n            test_list[person_folder] = [image_file]\n            \n    \nprint(\"Total images:\", tot_train_images + tot_test_images)\nprint(\"Total train images:\", tot_train_images)\nprint(\"Total test images:\", tot_test_images)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:47.412753Z","iopub.execute_input":"2023-09-11T18:38:47.413044Z","iopub.status.idle":"2023-09-11T18:38:47.704053Z","shell.execute_reply.started":"2023-09-11T18:38:47.413006Z","shell.execute_reply":"2023-09-11T18:38:47.703282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 49 Persons(Classes), 19 Images per person\n#### 832 Images (Some images missing)","metadata":{}},{"cell_type":"code","source":"total_images = tot_train_images + tot_test_images\ntotal_train_images = tot_train_images\ntotal_test_images = tot_test_images\ntotal_classes = 49","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:47.705544Z","iopub.execute_input":"2023-09-11T18:38:47.706029Z","iopub.status.idle":"2023-09-11T18:38:47.710657Z","shell.execute_reply.started":"2023-09-11T18:38:47.705990Z","shell.execute_reply":"2023-09-11T18:38:47.709663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Face detection and cropping","metadata":{}},{"cell_type":"code","source":"# Load OpenCV's pre-trained face detection cascade classifier\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:47.713378Z","iopub.execute_input":"2023-09-11T18:38:47.713888Z","iopub.status.idle":"2023-09-11T18:38:47.756576Z","shell.execute_reply.started":"2023-09-11T18:38:47.713848Z","shell.execute_reply":"2023-09-11T18:38:47.755804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Operating on the training data","metadata":{}},{"cell_type":"markdown","source":"## Creating Triplets from the Training data for training the Siamese Network using Triplet Loss\nTriplets of (anchor, postive, negative) are created using the training data. Positive is the same person and negative is a different person than the anchor.","metadata":{}},{"cell_type":"code","source":"def create_triplets(directory, folder_list, max_files=10):\n    triplets = []\n    folders = list(folder_list.keys())\n    \n    for folder in folders:\n        path = os.path.join(directory, folder)\n        files = list(os.listdir(path))[:max_files]\n        num_files = len(files)\n        \n        for i in range(num_files-1):\n            for j in range(i+1, num_files):\n                anchor = (folder, files[i])\n                positive = (folder, files[j])\n\n                neg_folder = folder\n                while neg_folder == folder:\n                    neg_folder = random.choice(folders)\n                    \n                num_negs = 2\n                files_chosen = []\n                \n                while(num_negs > 0):\n                    neg_file = folder_list[neg_folder][random.randint(0, len(folder_list[neg_folder])-1)]\n                    if(neg_file not in files_chosen):\n                        negative = (neg_folder, neg_file)\n                        triplets.append((anchor, positive, negative))\n                        num_negs -= 1\n                        files_chosen.append(neg_file)\n            \n    random.shuffle(triplets)\n    return triplets","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:47.757821Z","iopub.execute_input":"2023-09-11T18:38:47.758078Z","iopub.status.idle":"2023-09-11T18:38:47.768642Z","shell.execute_reply.started":"2023-09-11T18:38:47.758045Z","shell.execute_reply":"2023-09-11T18:38:47.767829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_triplets = create_triplets(dataset_folder, train_list)\n\nprint(\"Number of training triplets:\", len(train_triplets))\n\nprint(\"\\nExamples of triplets:\")\nfor i in range(5):\n    print(train_triplets[i])","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:47.769885Z","iopub.execute_input":"2023-09-11T18:38:47.770222Z","iopub.status.idle":"2023-09-11T18:38:47.829194Z","shell.execute_reply.started":"2023-09-11T18:38:47.770186Z","shell.execute_reply":"2023-09-11T18:38:47.828517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Batch-Generator¶\nUsed to obtain chunks/batches of triplets of (anchor, positive, negative) samples. ","metadata":{}},{"cell_type":"code","source":"def get_batch(triplet_list, batch_size=256, preprocess=True):\n    batch_steps = len(triplet_list)//batch_size\n    \n    for i in range(batch_steps+1):\n        anchor   = []\n        positive = []\n        negative = []\n        \n        j = i*batch_size\n        while j<(i+1)*batch_size and j<len(triplet_list):\n            a, p, n = triplet_list[j]\n            anchor.append(read_image(a))\n            positive.append(read_image(p))\n            negative.append(read_image(n))\n            \n            j+=1\n            \n        anchor = np.array(anchor)\n        positive = np.array(positive)\n        negative = np.array(negative)\n        \n        \n        if preprocess:\n            anchor = preprocess_input(anchor)\n            positive = preprocess_input(positive)\n            negative = preprocess_input(negative)\n        \n        yield ([anchor, positive, negative])","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:47.832333Z","iopub.execute_input":"2023-09-11T18:38:47.832885Z","iopub.status.idle":"2023-09-11T18:38:47.841158Z","shell.execute_reply.started":"2023-09-11T18:38:47.832845Z","shell.execute_reply":"2023-09-11T18:38:47.840433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting the data\nPlotting the data generated from get_batch()","metadata":{}},{"cell_type":"code","source":"num_plots = 6\n\nf, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n\nfor x in get_batch(train_triplets, batch_size=num_plots, preprocess=False):\n    a,p,n = x\n    for i in range(num_plots):\n        axes[i, 0].imshow(a[i])\n        axes[i, 1].imshow(p[i])\n        axes[i, 2].imshow(n[i])\n        i+=1\n    break","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:47.842585Z","iopub.execute_input":"2023-09-11T18:38:47.843114Z","iopub.status.idle":"2023-09-11T18:38:52.070842Z","shell.execute_reply.started":"2023-09-11T18:38:47.843077Z","shell.execute_reply":"2023-09-11T18:38:52.069222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the Siamese Network\nIn contrast to a typical Convolutional Neural Network (CNN), the Siamese Network doesn't categorize images into specific classes or labels. Instead, its primary task is to determine the dissimilarity or distance between any pair of provided images. When the two images share the same label, the network aims to adjust its parameters, including weights and biases, to minimize the distance between these two images. Conversely, if the images belong to distinct labels, the network should increase the distance between them.\n\n![](https://miro.medium.com/max/2000/1*05hUCDHhnl4hdjqvdVTHtw.png)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend, layers, metrics\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Model, Sequential\n\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:52.071833Z","iopub.execute_input":"2023-09-11T18:38:52.072079Z","iopub.status.idle":"2023-09-11T18:38:52.233084Z","shell.execute_reply.started":"2023-09-11T18:38:52.072047Z","shell.execute_reply":"2023-09-11T18:38:52.232190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating the encoder\nThe encoder's role is to transform the provided images into their respective feature vectors. To achieve this, we are utilizing a pre-trained Xception model, which is built upon the Inception_V3 model.","metadata":{}},{"cell_type":"code","source":"def get_encoder(input_shape):\n    \"\"\" Returns the image encoding model \"\"\"\n\n    pretrained_model = Xception(\n        input_shape=input_shape,\n        weights='imagenet',\n        include_top=False,\n        pooling='avg',\n    )\n    \n    for i in range(len(pretrained_model.layers)-27):\n        pretrained_model.layers[i].trainable = False\n\n    encode_model = Sequential([\n        pretrained_model,\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation=\"relu\"),\n        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n    ], name=\"Encode_Model\")\n    return encode_model","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:52.235881Z","iopub.execute_input":"2023-09-11T18:38:52.236155Z","iopub.status.idle":"2023-09-11T18:38:52.243219Z","shell.execute_reply.started":"2023-09-11T18:38:52.236121Z","shell.execute_reply":"2023-09-11T18:38:52.242332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We're creating a Siamese Network that takes 3 input images, (anchor, postive, negative) and uses the encoder above to encode the images to their feature vectors. Those features are passed to a distance layer which computes the distance between (anchor, positive) and (anchor, negative) pairs.","metadata":{}},{"cell_type":"code","source":"class DistanceLayer(layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def call(self, anchor, positive, negative):\n        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n        return (ap_distance, an_distance)\n    \n\ndef get_siamese_network(input_shape = (350, 350, 3)):\n    encoder = get_encoder(input_shape)\n    \n    # Input Layers for the images\n    anchor_input   = layers.Input(input_shape, name=\"Anchor_Input\")\n    positive_input = layers.Input(input_shape, name=\"Positive_Input\")\n    negative_input = layers.Input(input_shape, name=\"Negative_Input\")\n    \n    ## Generate the encodings (feature vectors) for the images\n    encoded_a = encoder(anchor_input)\n    encoded_p = encoder(positive_input)\n    encoded_n = encoder(negative_input)\n    \n    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n    distances = DistanceLayer()(\n        encoder(anchor_input),\n        encoder(positive_input),\n        encoder(negative_input)\n    )\n    \n    # Creating the Model\n    siamese_network = Model(\n        inputs  = [anchor_input, positive_input, negative_input],\n        outputs = distances,\n        name = \"Siamese_Network\"\n    )\n    return siamese_network\n\nsiamese_network = get_siamese_network()\nsiamese_network.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:38:52.247314Z","iopub.execute_input":"2023-09-11T18:38:52.247746Z","iopub.status.idle":"2023-09-11T18:39:00.642466Z","shell.execute_reply.started":"2023-09-11T18:38:52.247708Z","shell.execute_reply":"2023-09-11T18:39:00.641633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(siamese_network, show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:00.643585Z","iopub.execute_input":"2023-09-11T18:39:00.644046Z","iopub.status.idle":"2023-09-11T18:39:01.640694Z","shell.execute_reply.started":"2023-09-11T18:39:00.644013Z","shell.execute_reply":"2023-09-11T18:39:01.639826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the final Siamese Model class\nOur next step involves creating a model that utilizes a custom training loop and loss function. This model will allow us to calculate the triplet loss by utilizing the three embeddings generated by the Siamese network.","metadata":{}},{"cell_type":"code","source":"class SiameseModel(Model):\n    # Builds a Siamese model based on a base-model\n    def __init__(self, siamese_network, margin=1.0):\n        super(SiameseModel, self).__init__()\n        \n        self.margin = margin\n        self.siamese_network = siamese_network\n        self.loss_tracker = metrics.Mean(name=\"loss\")\n\n    def call(self, inputs):\n        return self.siamese_network(inputs)\n\n    def train_step(self, data):\n        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n        with tf.GradientTape() as tape:\n            loss = self._compute_loss(data)\n            \n        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n        \n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def test_step(self, data):\n        loss = self._compute_loss(data)\n        \n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def _compute_loss(self, data):\n        # Get the two distances from the network, then compute the triplet loss\n        ap_distance, an_distance = self.siamese_network(data)\n        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n        return loss\n\n    @property\n    def metrics(self):\n        # We need to list our metrics so the reset_states() can be called automatically.\n        return [self.loss_tracker]","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:01.642768Z","iopub.execute_input":"2023-09-11T18:39:01.643084Z","iopub.status.idle":"2023-09-11T18:39:01.656425Z","shell.execute_reply.started":"2023-09-11T18:39:01.643043Z","shell.execute_reply":"2023-09-11T18:39:01.655493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_model = SiameseModel(siamese_network)\n\noptimizer = Adam(learning_rate=1e-3, epsilon=1e-01)\nsiamese_model.compile(optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:01.658122Z","iopub.execute_input":"2023-09-11T18:39:01.658511Z","iopub.status.idle":"2023-09-11T18:39:01.671325Z","shell.execute_reply.started":"2023-09-11T18:39:01.658359Z","shell.execute_reply":"2023-09-11T18:39:01.670603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Siamese model","metadata":{}},{"cell_type":"code","source":"save_all = False\nepochs = 30\nbatch_size = 128\n\ntrain_loss = []\n\nfor epoch in range(1, epochs+1):\n    t = time.time()\n    \n    # Training the model on train data\n    epoch_loss = []\n    for data in get_batch(train_triplets, batch_size=batch_size):\n        loss = siamese_model.train_on_batch(data)\n        epoch_loss.append(loss)\n    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n    train_loss.append(epoch_loss)\n\n    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n    print(f\"Loss on train    = {epoch_loss:.5f}\")\n    \n    \n\n# Saving the model after all epochs run\nsiamese_model.save_weights(\"siamese_model\")","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:01.672345Z","iopub.execute_input":"2023-09-11T18:39:01.672545Z","iopub.status.idle":"2023-09-11T18:39:01.684853Z","shell.execute_reply.started":"2023-09-11T18:39:01.672521Z","shell.execute_reply":"2023-09-11T18:39:01.684059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using the Siamese model\nHaving completed the training of our model, our next step is to extract the encoder. This will enable us to encode images, using the generated feature vectors to calculate the distance between them.","metadata":{}},{"cell_type":"markdown","source":"### Loading the saved model","metadata":{}},{"cell_type":"code","source":"# siamese_model = SiameseModel(siamese_network)\n# optimizer = Adam(learning_rate=1e-3, epsilon=1e-01)\n# siamese_model.compile(optimizer=optimizer)\n# siamese_model.load_weights(\"/kaggle/input/output/results/siamese_model\")","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:01.686337Z","iopub.execute_input":"2023-09-11T18:39:01.686598Z","iopub.status.idle":"2023-09-11T18:39:04.167717Z","shell.execute_reply.started":"2023-09-11T18:39:01.686565Z","shell.execute_reply":"2023-09-11T18:39:04.166994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_encoder(model):\n    encoder = get_encoder((350, 350, 3))\n    i=0\n    for e_layer in model.layers[0].layers[3].layers:\n        layer_weight = e_layer.get_weights()\n        encoder.layers[i].set_weights(layer_weight)\n        i+=1\n    return encoder\n\n\nencoder = extract_encoder(siamese_model)\nencoder.save_weights(\"encoder\")\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:04.169191Z","iopub.execute_input":"2023-09-11T18:39:04.169450Z","iopub.status.idle":"2023-09-11T18:39:06.274988Z","shell.execute_reply.started":"2023-09-11T18:39:04.169415Z","shell.execute_reply":"2023-09-11T18:39:06.274194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the training data for training the classifier","metadata":{}},{"cell_type":"code","source":"train_image_list = []\nfor person_folder in train_list.keys():\n    temp = []\n    for image_file in train_list[person_folder]:\n        b = read_image((person_folder, image_file))\n        temp.append(b)\n    train_image_list.append(temp)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:06.276494Z","iopub.execute_input":"2023-09-11T18:39:06.276755Z","iopub.status.idle":"2023-09-11T18:39:52.901912Z","shell.execute_reply.started":"2023-09-11T18:39:06.276721Z","shell.execute_reply":"2023-09-11T18:39:52.901214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum = 0\nlis = []\nfrequency = {}\nfor i in range(0, len(train_image_list)):\n    sum += ((len(train_image_list[i]))*(len(train_image_list[i]) - 1))/2\n    lis.append(len(train_image_list[i]))\n\nfor item in lis:\n   # checking the element in dictionary\n   if item in frequency:\n      # incrementing the count\n      frequency[item] += 1\n   else:\n      # initializing the count\n      frequency[item] = 1\ntot_val = 0\nfor key in frequency:\n    tot_val += key*frequency[key]\nfinal_freq = {}\nfor key in frequency:\n    final_freq[key] = key*frequency[key]/tot_val\n\n\n# printing the frequency\nprint(frequency)\nprint(final_freq)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:52.903210Z","iopub.execute_input":"2023-09-11T18:39:52.903701Z","iopub.status.idle":"2023-09-11T18:39:52.914101Z","shell.execute_reply.started":"2023-09-11T18:39:52.903662Z","shell.execute_reply":"2023-09-11T18:39:52.913249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating pairs of images from the training dataset (to train the classifier)","metadata":{}},{"cell_type":"code","source":"random.seed(42)\nnewX1 = []\nnewX2 = []\nnewY = []\nfor i in range(len(train_image_list)):\n    for j in range(0, len(train_image_list[i])):\n        for k in range(0, j):\n            newX1.append(train_image_list[i][k])\n            newX2.append(train_image_list[i][j])\n            newY.append(0)\n    \n    for u in range(0, len(train_image_list[i])):\n        step = 1\n        step = round((final_freq[len(train_image_list[i])]*4096)/frequency[len(train_image_list[i])])\n        no_of_iter = round(step/len(train_image_list[i]))\n        for l in range(0, no_of_iter):\n            numbers = list(range(0, i)) + list(range(i+1, 49))\n            r = random.choice(numbers)\n            g = random.randint(0, len(train_image_list[r]) - 1)\n            newX1.append(train_image_list[i][u])\n            newX2.append(train_image_list[r][g])\n            newY.append(1)\nfor i in range(0, 214):\n        \n    numbers = list(range(0,i%49)) + list(range(i%49 + 1,49))\n    r = random.choice(numbers)\n    uu = random.randint(0,len(train_image_list[i%49])-1)\n    g = random.randint(0,len(train_image_list[r])-1)\n    newX1.append(train_image_list[i%49][uu])\n    newX2.append(train_image_list[r][g])\n    newY.append(1)\nprint(len(newY))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:52.915475Z","iopub.execute_input":"2023-09-11T18:39:52.915781Z","iopub.status.idle":"2023-09-11T18:39:52.966390Z","shell.execute_reply.started":"2023-09-11T18:39:52.915745Z","shell.execute_reply":"2023-09-11T18:39:52.965621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = list(zip(newX1, newX2, newY))\n\nrandom.shuffle(c)\n\na, b, y = zip(*c)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:52.967795Z","iopub.execute_input":"2023-09-11T18:39:52.968090Z","iopub.status.idle":"2023-09-11T18:39:52.985857Z","shell.execute_reply.started":"2023-09-11T18:39:52.968053Z","shell.execute_reply":"2023-09-11T18:39:52.984995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting features using the encoder of the Siamese Model","metadata":{}},{"cell_type":"code","source":"# output1=base_model.predict(np.array(a)/255)\n# output2=base_model.predict(np.array(b)/255)\noutput1 = []\noutput2 = []\nfor i in range(1, len(a)//256 + 1):\n    a1 = a[(i-1)*256 : i*256]\n    b1 = b[(i-1)*256 : i*256]\n    output1.extend(encoder.predict(np.array(a1)/255))\n    output2.extend(encoder.predict(np.array(b1)/255))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:39:52.987051Z","iopub.execute_input":"2023-09-11T18:39:52.987330Z","iopub.status.idle":"2023-09-11T18:42:58.068669Z","shell.execute_reply.started":"2023-09-11T18:39:52.987293Z","shell.execute_reply":"2023-09-11T18:42:58.067769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indexes1=[i for i,x in enumerate(y) if x == 1]\nindexes0=[i for i,x in enumerate(y) if x == 0]","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:42:58.070082Z","iopub.execute_input":"2023-09-11T18:42:58.070369Z","iopub.status.idle":"2023-09-11T18:42:58.078637Z","shell.execute_reply.started":"2023-09-11T18:42:58.070334Z","shell.execute_reply":"2023-09-11T18:42:58.077840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(output2))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:42:58.079890Z","iopub.execute_input":"2023-09-11T18:42:58.080174Z","iopub.status.idle":"2023-09-11T18:42:58.101202Z","shell.execute_reply.started":"2023-09-11T18:42:58.080138Z","shell.execute_reply":"2023-09-11T18:42:58.100483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features Subtraction\n\n- Getting absolute value of the difference between feature vectors of two images\n- Plotting graphs for positive and negative image pairs","metadata":{}},{"cell_type":"code","source":"arr=[]\nsu=[]\nfor s in range(len(output1)):\n    oo = np.abs(np.subtract(np.array(output1[s]),np.array(output2[s])))\n    arr.append(oo)\n    su.append(oo.sum())\n    \na = np.array(su)\nsu1=list(a[indexes1])\nsu0=list(a[indexes0])\n\nfig, axs = plt.subplots(1, 2)\nfig.set_size_inches(18, 4)\nfig.suptitle(\"Sum differences\")\naxs[0].plot(list(range(4096)),su1, list(range(4096)),su0)\naxs[0].legend([\"different people\", \"same person\"])\n#axs[0].title(\"Euclidean distance\")\naxs[1].plot(list(range(8192)),su)\naxs[1].legend([\"overall variation\"])\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:42:58.102388Z","iopub.execute_input":"2023-09-11T18:42:58.103044Z","iopub.status.idle":"2023-09-11T18:42:58.942556Z","shell.execute_reply.started":"2023-09-11T18:42:58.103007Z","shell.execute_reply":"2023-09-11T18:42:58.941811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using a simple neural network for classifying the image pairs as those of the same person or those of different people¶","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nimport tensorflow\n\n\ndef distance(vecs):\n    x, y = vecs\n    x = K.l2_normalize(x, axis=-1)\n    y = K.l2_normalize(y, axis=-1)\n    \n    return K.abs(x-y)\n\n\nfeaturesA=Input(256, )\nfeaturesB=Input(256, )\ndistance= Lambda(distance)([featuresA,featuresB])\n\nx= Dense(96, activation=\"relu\")(distance)\nx= Dropout(0.3)(x)\nx= Dense(64)(x)\noutputs = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=[featuresA, featuresB],outputs=outputs)\nmodel.compile(loss='binary_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:42:58.961126Z","iopub.execute_input":"2023-09-11T18:42:58.961466Z","iopub.status.idle":"2023-09-11T18:42:59.022402Z","shell.execute_reply.started":"2023-09-11T18:42:58.961429Z","shell.execute_reply":"2023-09-11T18:42:59.021538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting the classifier and checking the validation accuracy","metadata":{}},{"cell_type":"code","source":"history=model.fit([np.array(output1)[:6144], np.array(output2)[:6144]],np.array(y)[:6144],validation_data=([np.array(output1)[6144:], np.array(output2)[6144:]],np.array(y)[6144:]), epochs=10, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:42:59.023881Z","iopub.execute_input":"2023-09-11T18:42:59.024164Z","iopub.status.idle":"2023-09-11T18:43:10.674468Z","shell.execute_reply.started":"2023-09-11T18:42:59.024127Z","shell.execute_reply":"2023-09-11T18:43:10.673565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2)\nfig.set_size_inches(18, 4)\nfig.suptitle(\"Overfitting analysis\")\naxs[0].plot(list(range(1,11)), history.history['val_accuracy'], list(range(1,11)), history.history['accuracy'])\n\naxs[0].title.set_text(\"Accuracy\")\naxs[0].legend([\"validation accuracy\", \"training accuracy\"])\naxs[1].plot(list(range(1,11)), history.history['val_loss'], list(range(1,11)), history.history['loss'])\naxs[1].title.set_text('Loss')\naxs[1].legend([\"validation loss\", \"trainig loss\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:10.675883Z","iopub.execute_input":"2023-09-11T18:43:10.676164Z","iopub.status.idle":"2023-09-11T18:43:11.073514Z","shell.execute_reply.started":"2023-09-11T18:43:10.676127Z","shell.execute_reply":"2023-09-11T18:43:11.072816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"test_image_list = []\nfor person_folder in test_list.keys():\n    temp = []\n    for image_file in test_list[person_folder]:\n        b = read_image((person_folder, image_file))\n        temp.append(b)\n    test_image_list.append(temp)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:11.074778Z","iopub.execute_input":"2023-09-11T18:43:11.075666Z","iopub.status.idle":"2023-09-11T18:43:24.267396Z","shell.execute_reply.started":"2023-09-11T18:43:11.075625Z","shell.execute_reply":"2023-09-11T18:43:24.266453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum = 0\nlis = []\nfrequency = {}\nfor i in range(0, len(test_image_list)):\n    sum += ((len(test_image_list[i]))*(len(test_image_list[i]) - 1))/2\n    lis.append(len(test_image_list[i]))\n\nfor item in lis:\n   # checking the element in dictionary\n   if item in frequency:\n      # incrementing the count\n      frequency[item] += 1\n   else:\n      # initializing the count\n      frequency[item] = 1\ntot_val = 0\nfor key in frequency:\n    tot_val += key*frequency[key]\nfinal_freq = {}\nfor key in frequency:\n    final_freq[key] = key*frequency[key]/tot_val\n\n\n# printing the frequency\nprint(final_freq)\nprint(frequency)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:24.268737Z","iopub.execute_input":"2023-09-11T18:43:24.269176Z","iopub.status.idle":"2023-09-11T18:43:24.279654Z","shell.execute_reply.started":"2023-09-11T18:43:24.269138Z","shell.execute_reply":"2023-09-11T18:43:24.278615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_image_list))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:24.284578Z","iopub.execute_input":"2023-09-11T18:43:24.284805Z","iopub.status.idle":"2023-09-11T18:43:24.294705Z","shell.execute_reply.started":"2023-09-11T18:43:24.284778Z","shell.execute_reply":"2023-09-11T18:43:24.293704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating pairs of images from the test dataset for evaluating the entire pipeline","metadata":{}},{"cell_type":"code","source":"random.seed(42)\nnewX1_test = []\nnewX2_test = []\nnewY_test = []\nfor i in range(len(test_image_list)):\n    for j in range(0, len(test_image_list[i])):\n        for k in range(0, j):\n            newX1_test.append(test_image_list[i][k])\n            newX2_test.append(test_image_list[i][j])\n            newY_test.append(0)\n    \n    for u in range(0, len(test_image_list[i])):\n        step = 1\n        step = round((final_freq[len(test_image_list[i])]*264)/frequency[len(test_image_list[i])])\n        no_of_iter = round(step/len(test_image_list[i]))\n        for l in range(0, 1):\n            numbers = list(range(0, i)) + list(range(i+1, 49))\n            r = random.choice(numbers)\n            g = random.randint(0, len(test_image_list[r]) - 1)\n            newX1_test.append(test_image_list[i][u])\n            newX2_test.append(test_image_list[r][g])\n            newY_test.append(1)\nfor i in range(0, 79):\n        \n    numbers = list(range(0,i%49)) + list(range(i%49 + 1,49))\n    r = random.choice(numbers)\n    uu = random.randint(0,len(test_image_list[i%49])-1)\n    g = random.randint(0,len(test_image_list[r])-1)\n    newX1_test.append(test_image_list[i%49][uu])\n    newX2_test.append(test_image_list[r][g])\n    newY_test.append(1)\nprint(len(newY_test))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:24.296037Z","iopub.execute_input":"2023-09-11T18:43:24.296419Z","iopub.status.idle":"2023-09-11T18:43:24.314590Z","shell.execute_reply.started":"2023-09-11T18:43:24.296383Z","shell.execute_reply":"2023-09-11T18:43:24.313814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_test = list(zip(newX1_test, newX2_test, newY_test))\n\nrandom.shuffle(c_test)\n\na_test, b_test, y_test = zip(*c_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:24.315995Z","iopub.execute_input":"2023-09-11T18:43:24.316595Z","iopub.status.idle":"2023-09-11T18:43:24.329158Z","shell.execute_reply.started":"2023-09-11T18:43:24.316559Z","shell.execute_reply":"2023-09-11T18:43:24.328432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor i in range(0, len(y_test)):\n    if(y_test[i] == 0):\n        count+=1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:24.330661Z","iopub.execute_input":"2023-09-11T18:43:24.331591Z","iopub.status.idle":"2023-09-11T18:43:24.340086Z","shell.execute_reply.started":"2023-09-11T18:43:24.331554Z","shell.execute_reply":"2023-09-11T18:43:24.339301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(a_test))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:24.341319Z","iopub.execute_input":"2023-09-11T18:43:24.341695Z","iopub.status.idle":"2023-09-11T18:43:24.349699Z","shell.execute_reply.started":"2023-09-11T18:43:24.341659Z","shell.execute_reply":"2023-09-11T18:43:24.348993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting features using the encoder of the Siamese Model","metadata":{}},{"cell_type":"code","source":"output1_test = []\noutput2_test = []\nfor i in range(1, len(a_test)//264 + 1):\n    a1_test = a_test[(i-1)*264 : i*264]\n    b1_test = b_test[(i-1)*264 : i*264]\n    output1_test.extend(encoder.predict(np.array(a1_test)/255))\n    output2_test.extend(encoder.predict(np.array(b1_test)/255))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:24.350969Z","iopub.execute_input":"2023-09-11T18:43:24.351851Z","iopub.status.idle":"2023-09-11T18:43:37.796040Z","shell.execute_reply.started":"2023-09-11T18:43:24.351814Z","shell.execute_reply":"2023-09-11T18:43:37.795190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indexes1_test=[i for i,x in enumerate(y_test) if x == 1]\nindexes0_test=[i for i,x in enumerate(y_test) if x == 0]","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:37.798443Z","iopub.execute_input":"2023-09-11T18:43:37.798670Z","iopub.status.idle":"2023-09-11T18:43:37.803235Z","shell.execute_reply.started":"2023-09-11T18:43:37.798643Z","shell.execute_reply":"2023-09-11T18:43:37.802415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using the classifier for final training and evaluation","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nimport tensorflow\n\n\ndef distance(vecs):\n    x, y = vecs\n    x = K.l2_normalize(x, axis=-1)\n    y = K.l2_normalize(y, axis=-1)\n    \n    return K.abs(x-y)\n\n\nfeaturesA=Input(256, )\nfeaturesB=Input(256, )\ndistance= Lambda(distance)([featuresA,featuresB])\n\nx= Dense(96, activation=\"relu\")(distance)\nx= Dropout(0.3)(x)\nx= Dense(64)(x)\noutputs = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=[featuresA, featuresB],outputs=outputs)\nmodel.compile(loss='binary_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:37.804678Z","iopub.execute_input":"2023-09-11T18:43:37.805125Z","iopub.status.idle":"2023-09-11T18:43:37.932421Z","shell.execute_reply.started":"2023-09-11T18:43:37.805066Z","shell.execute_reply":"2023-09-11T18:43:37.931619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(output1))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:37.933709Z","iopub.execute_input":"2023-09-11T18:43:37.934444Z","iopub.status.idle":"2023-09-11T18:43:37.940103Z","shell.execute_reply.started":"2023-09-11T18:43:37.934404Z","shell.execute_reply":"2023-09-11T18:43:37.939115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting the classifier on the entire training data","metadata":{}},{"cell_type":"code","source":"history=model.fit([np.array(output1)[:8192], np.array(output2)[:8192]],np.array(y)[:8192], epochs=15, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:37.941451Z","iopub.execute_input":"2023-09-11T18:43:37.942153Z","iopub.status.idle":"2023-09-11T18:43:46.504655Z","shell.execute_reply.started":"2023-09-11T18:43:37.942115Z","shell.execute_reply":"2023-09-11T18:43:46.503882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Obtaining final test results on the entire test data","metadata":{}},{"cell_type":"code","source":"test_res = model.evaluate([np.array(output1_test)[:528], np.array(output2_test)[:528]],np.array(y_test)[:528], batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T18:43:46.507888Z","iopub.execute_input":"2023-09-11T18:43:46.508140Z","iopub.status.idle":"2023-09-11T18:43:46.790194Z","shell.execute_reply.started":"2023-09-11T18:43:46.508111Z","shell.execute_reply":"2023-09-11T18:43:46.789351Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}