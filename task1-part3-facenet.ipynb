{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Face Verification using PreTrained FaceNet model\n\n\nWe have used the FaceNet model developed by Hiroki Taniai and availble in [this repository](https://drive.google.com/open?id=1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:38:55.592859Z","iopub.execute_input":"2023-09-12T07:38:55.593235Z","iopub.status.idle":"2023-09-12T07:38:55.599726Z","shell.execute_reply.started":"2023-09-12T07:38:55.593187Z","shell.execute_reply":"2023-09-12T07:38:55.598817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, f1_score, make_scorer\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import Normalizer, LabelEncoder\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import Model\nfrom tensorflow.keras import models\nfrom tensorflow.keras import Sequential\nimport random\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-12T07:38:55.601523Z","iopub.execute_input":"2023-09-12T07:38:55.602161Z","iopub.status.idle":"2023-09-12T07:38:55.613297Z","shell.execute_reply.started":"2023-09-12T07:38:55.602113Z","shell.execute_reply":"2023-09-12T07:38:55.612266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Face detection and cropping","metadata":{}},{"cell_type":"code","source":"# Load OpenCV's pre-trained face detection cascade classifier\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:38:55.615653Z","iopub.execute_input":"2023-09-12T07:38:55.616104Z","iopub.status.idle":"2023-09-12T07:38:55.648856Z","shell.execute_reply.started":"2023-09-12T07:38:55.616060Z","shell.execute_reply":"2023-09-12T07:38:55.648126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data","metadata":{}},{"cell_type":"code","source":"# Set paths\ndataset_folder = '/kaggle/input/iiitb-faces/IIITB-FACES'\ntest_filepaths = [] # Contains the absolute paths of test images\ntrain_filepaths = []# Contains the absolute paths of train images\n\n# Loop through each person's folder\nfor person_folder in os.listdir(dataset_folder):\n    person_path = os.path.join(dataset_folder, person_folder)\n    person_images = [os.path.join(person_path, image_file) for image_file in os.listdir(person_path)]\n\n    random.shuffle(person_images)\n    \n    # Calculate split point based on 80-20 ratio\n    split_index = int(0.8 * len(person_images))\n    \n    # Split images into train and test\n    train_filepaths.append(person_images[:split_index])\n    test_filepaths.append(person_images[split_index:])\n\ntrain_image_list = []\nfor row in train_filepaths:\n    train_image_list.extend(row)\n\ntest_image_list = []\nfor row in test_filepaths:\n    test_image_list.extend(row)\n\nprint(\"total people: \", len(train_filepaths))\nprint(\"Total images:\", len(train_image_list)+len(test_image_list))\nprint(\"Total train images:\", len(train_image_list))\nprint(\"Total test images:\", len(test_image_list))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:38:55.651558Z","iopub.execute_input":"2023-09-12T07:38:55.652174Z","iopub.status.idle":"2023-09-12T07:38:55.705868Z","shell.execute_reply.started":"2023-09-12T07:38:55.652134Z","shell.execute_reply":"2023-09-12T07:38:55.705156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformed_train_filepaths = []\nfor filename in train_filepaths:\n    temp = []\n    for imagename in filename:\n        img = cv2.imread(imagename)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n\n        faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n        face_image = img\n        if(len(faces) > 0):\n            xf, yf, wf, hf = faces[0]\n            face_image = img[yf:yf+hf, xf:xf+wf]\n        face_image = cv2.resize(img, (224, 224))\n        \n\n        temp.append(face_image)\n    transformed_train_filepaths.append(temp)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T07:38:55.708927Z","iopub.execute_input":"2023-09-12T07:38:55.709200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(transformed_train_filepaths))\ntransformed_train_image_list = []\nfor row in transformed_train_filepaths:\n    transformed_train_image_list.extend(row)\nprint(len(transformed_train_image_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum = 0\nlis = []\nfrequency = {}\nfor i in range(0, len(transformed_train_filepaths)):\n    sum += ((len(transformed_train_filepaths[i]))*(len(transformed_train_filepaths[i]) - 1))/2\n    lis.append(len(transformed_train_filepaths[i]))\n\nfor item in lis:\n   # checking the element in dictionary\n   if item in frequency:\n      # incrementing the count\n      frequency[item] += 1\n   else:\n      # initializing the count\n      frequency[item] = 1\ntot_val = 0\nfor key in frequency:\n    tot_val += key*frequency[key]\nfinal_freq = {}\nfor key in frequency:\n    final_freq[key] = key*frequency[key]/tot_val\n\n\n# printing the frequency\nprint(final_freq)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating pairs of images from the training dataset (to train the classifier)","metadata":{}},{"cell_type":"code","source":"random.seed(42)\nnewX1 = []\nnewX2 = []\nnewY = []\nfor i in range(len(transformed_train_filepaths)):\n    \n    for j in range(0, len(transformed_train_filepaths[i])):\n        for k in range(0, j):\n            newX1.append(transformed_train_filepaths[i][k])\n            newX2.append(transformed_train_filepaths[i][j])\n            newY.append(0)\n    \n    for u in range(0, len(transformed_train_filepaths[i])):\n        step = 1\n        step = round((final_freq[len(transformed_train_filepaths[i])]*4096)/frequency[len(transformed_train_filepaths[i])])\n        no_of_iter = round(step/len(transformed_train_filepaths[i]))\n        for l in range(0, no_of_iter):\n            numbers = list(range(0, i)) + list(range(i+1, 49))\n            r = random.choice(numbers)\n            g = random.randint(0, len(transformed_train_filepaths[r]) - 1)\n            newX1.append(transformed_train_filepaths[i][u])\n            newX2.append(transformed_train_filepaths[r][g])\n            newY.append(1)\nfor i in range(0, 214):\n        \n    numbers = list(range(0,i%49)) + list(range(i%49 + 1,49))\n    r = random.choice(numbers)\n    uu = random.randint(0,len(transformed_train_filepaths[i%49])-1)\n    g = random.randint(0,len(transformed_train_filepaths[r])-1)\n    newX1.append(transformed_train_filepaths[i%49][uu])\n    newX2.append(transformed_train_filepaths[r][g])\n    newY.append(1)\nprint(len(newY))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = list(zip(newX1, newX2, newY))\n\nrandom.shuffle(c)\n\na, b, y = zip(*c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(a))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting features of images using FaceNet","metadata":{}},{"cell_type":"code","source":"base_model = models.load_model('/kaggle/input/facenet-keras/facenet_keras.h5')\n\nbase_model.load_weights(\"/kaggle/input/facenet-keras/facenet_keras_weights.h5\")\nbase_model.trainable=False\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output1 = []\noutput2 = []\nfor i in range(1, len(a)//1024 + 1):\n    a1 = a[(i-1)*1024 : i*1024]\n    b1 = b[(i-1)*1024 : i*1024]\n    output1.extend(base_model.predict(np.array(a1)/255))\n    output2.extend(base_model.predict(np.array(b1)/255))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indexes1=[i for i,x in enumerate(y) if x == 1]\nindexes0=[i for i,x in enumerate(y) if x == 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(output2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features Subtraction\n\n- Getting absolute value of the difference between feature vectors of two images \n- Plotting graphs for positive and negative image pairs","metadata":{}},{"cell_type":"code","source":"arr=[]\nsu=[]\nfor s in range(len(output1)):\n    oo = np.abs(np.subtract(np.array(output1[s]),np.array(output2[s])))\n    arr.append(oo)\n    su.append(oo.sum())\n    \na = np.array(su)\nsu1=list(a[indexes1])\nsu0=list(a[indexes0])\n\nfig, axs = plt.subplots(1, 2)\nfig.set_size_inches(18, 4)\nfig.suptitle(\"Sum differences\")\naxs[0].plot(list(range(4096)),su1, list(range(4096)),su0)\naxs[0].legend([\"different people\", \"same person\"])\n#axs[0].title(\"Euclidean distance\")\naxs[1].plot(list(range(8192)),su)\naxs[1].legend([\"overall variation\"])\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using a simple neural network for classifying the image pairs as those of the same person or those of different people","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nimport tensorflow\n\n\ndef distance(vecs):\n    x, y = vecs\n    x = K.l2_normalize(x, axis=-1)\n    y = K.l2_normalize(y, axis=-1)\n    \n    return K.abs(x-y)\n\n\nfeaturesA=Input(128, )\nfeaturesB=Input(128, )\ndistance= Lambda(distance)([featuresA,featuresB])\n\nx= Dense(96, activation=\"relu\")(distance)\nx= Dropout(0.3)(x)\nx= Dense(64)(x)\noutputs = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=[featuresA, featuresB],outputs=outputs)\nmodel.compile(loss='binary_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\nmodel.summary()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting the classifier and checking the validation accuracy","metadata":{}},{"cell_type":"code","source":"history=model.fit([np.array(output1)[:6144], np.array(output2)[:6144]],np.array(y)[:6144],validation_data=([np.array(output1)[6144:], np.array(output2)[6144:]],np.array(y)[6144:]), epochs=10, batch_size=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2)\nfig.set_size_inches(18, 4)\nfig.suptitle(\"Overfitting analysis\")\naxs[0].plot(list(range(1,11)), history.history['val_accuracy'], list(range(1,11)), history.history['accuracy'])\n\naxs[0].title.set_text(\"Accuracy\")\naxs[0].legend([\"validation accuracy\", \"training accuracy\"])\naxs[1].plot(list(range(1,11)), history.history['val_loss'], list(range(1,11)), history.history['loss'])\naxs[1].title.set_text('Loss')\naxs[1].legend([\"validation loss\", \"trainig loss\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"transformed_test_filepaths = []\nfor filename in test_filepaths:\n    temp = []\n    for imagename in filename:\n        img = cv2.imread(imagename)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n\n        faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n        face_image = img\n        if(len(faces) > 0):\n            xf, yf, wf, hf = faces[0]\n            face_image = img[yf:yf+hf, xf:xf+wf]\n        face_image = cv2.resize(img, (224, 224))\n        \n\n        temp.append(face_image)\n    transformed_test_filepaths.append(temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(transformed_test_filepaths))\ntransformed_test_image_list = []\nfor row in transformed_test_filepaths:\n    transformed_test_image_list.extend(row)\nprint(len(transformed_test_image_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum = 0\nlis = []\nfrequency = {}\nfor i in range(0, len(transformed_test_filepaths)):\n    sum += ((len(transformed_test_filepaths[i]))*(len(transformed_test_filepaths[i]) - 1))/2\n    lis.append(len(transformed_test_filepaths[i]))\n\nfor item in lis:\n   # checking the element in dictionary\n   if item in frequency:\n      # incrementing the count\n      frequency[item] += 1\n   else:\n      # initializing the count\n      frequency[item] = 1\ntot_val = 0\nfor key in frequency:\n    tot_val += key*frequency[key]\nfinal_freq = {}\nfor key in frequency:\n    final_freq[key] = key*frequency[key]/tot_val\n\n\n# printing the frequency\nprint(final_freq)\nprint(frequency)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(transformed_test_filepaths))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating pairs of images from the test dataset for evaluating the entire pipeline","metadata":{}},{"cell_type":"code","source":"random.seed(42)\nnewX1_test = []\nnewX2_test = []\nnewY_test = []\nfor i in range(len(transformed_test_filepaths)):\n\n    for j in range(0, len(transformed_test_filepaths[i])):\n        for k in range(0, j):\n            newX1_test.append(transformed_test_filepaths[i][k])\n            newX2_test.append(transformed_test_filepaths[i][j])\n            newY_test.append(0)\n    \n    for u in range(0, len(transformed_test_filepaths[i])):\n        step = 1\n        step = round((final_freq[len(transformed_test_filepaths[i])]*264)/frequency[len(transformed_test_filepaths[i])])\n        no_of_iter = round(step/len(transformed_test_filepaths[i]))\n        for l in range(0, 1):\n            numbers = list(range(0, i)) + list(range(i+1, 49))\n            r = random.choice(numbers)\n            g = random.randint(0, len(transformed_test_filepaths[r]) - 1)\n            newX1_test.append(transformed_test_filepaths[i][u])\n            newX2_test.append(transformed_test_filepaths[r][g])\n            newY_test.append(1)\nfor i in range(0, 79):\n        \n    numbers = list(range(0,i%49)) + list(range(i%49 + 1,49))\n    r = random.choice(numbers)\n    uu = random.randint(0,len(transformed_test_filepaths[i%49])-1)\n    g = random.randint(0,len(transformed_test_filepaths[r])-1)\n    newX1_test.append(transformed_test_filepaths[i%49][uu])\n    newX2_test.append(transformed_test_filepaths[r][g])\n    newY_test.append(1)\nprint(len(newY_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_test = list(zip(newX1_test, newX2_test, newY_test))\n\nrandom.shuffle(c_test)\n\na_test, b_test, y_test = zip(*c_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor i in range(0, len(y_test)):\n    if(y_test[i] == 0):\n        count+=1\nprint(count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(a_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting features of images using FaceNet","metadata":{}},{"cell_type":"code","source":"output1_test = []\noutput2_test = []\nfor i in range(1, len(a_test)//264 + 1):\n    a1_test = a_test[(i-1)*264 : i*264]\n    b1_test = b_test[(i-1)*264 : i*264]\n    output1_test.extend(base_model.predict(np.array(a1_test)/255))\n    output2_test.extend(base_model.predict(np.array(b1_test)/255))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indexes1_test=[i for i,x in enumerate(y_test) if x == 1]\nindexes0_test=[i for i,x in enumerate(y_test) if x == 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using the classifier for final training and evaluation","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nimport tensorflow\n\n\ndef distance(vecs):\n    x, y = vecs\n    x = K.l2_normalize(x, axis=-1)\n    y = K.l2_normalize(y, axis=-1)\n    \n    return K.abs(x-y)\n\n\nfeaturesA=Input(128, )\nfeaturesB=Input(128, )\ndistance= Lambda(distance)([featuresA,featuresB])\n\nx= Dense(96, activation=\"relu\")(distance)\nx= Dropout(0.3)(x)\nx= Dense(64)(x)\noutputs = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=[featuresA, featuresB],outputs=outputs)\nmodel.compile(loss='binary_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(output1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting the classifier on the entire training data","metadata":{}},{"cell_type":"code","source":"history=model.fit([np.array(output1)[:8192], np.array(output2)[:8192]],np.array(y)[:8192], epochs=8, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Obtaining final test results on the entire test data","metadata":{}},{"cell_type":"code","source":"test_res = model.evaluate([np.array(output1_test)[:528], np.array(output2_test)[:528]],np.array(y_test)[:528], batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}